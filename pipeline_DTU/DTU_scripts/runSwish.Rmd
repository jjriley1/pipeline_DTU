---
title: "runSwish"
output: 
  html_document:
    df_print: paged
---

N.b. this script must be run in the "R-swish" environment:
"/shared/sudlab1/General/apps/conda/conda-install/envs/R-swish"

```{r load_libs, warning=FALSE}
library(fishpond)
library(tximeta)
library(dplyr)
library(samr)
library(qvalue)
library(stringr)
library(tidyr)
library(data.table)
```

Load in the configs / run-specific information

```{r load_configs}
#load config and info file
pipeline_yml = yaml::read_yaml("../../pipeline.yml")

#determine which comparison we are currently doing
folder_name = basename(getwd())

#get formula
formula = read.table(paste0(folder_name, ".txt")) %>% unlist() %>% unname()

#we need to know what var1 values to filter by
filter_by_var1 = str_split(folder_name, "_in_")[[1]][1] %>% str_split("_vs_") %>% unlist()

#if there are 2 'vs' in the name then we are doing the
#interaction comparison, i.e. ~X + Y + X:Y
do_interaction = ifelse((length(grep("vs", str_split(folder_name, "_")[[1]])) == 2), TRUE, FALSE)

#if there is an 'in' present then we will need to filter
#the sample_table later, so we need to know if so
do_filter_by_var2 = "in" %in% str_split(folder_name, "_")[[1]]

#we also need to know what to filter by, e.g. wt or mutant, or both
if (do_filter_by_var2) {
  filter_by_var2 = str_split(folder_name, "_in_")[[1]][2] %>% str_split("_vs_") %>% unlist()
}
```

Generate sample table for tximport

```{r sample_table_from_sf}
#list all salmon files in quantification directory

quant_dir = "../../quantification.dir"

file_namings = fread("../../file_naming.tsv", header=F)

comparison = as.character(str_split(basename(getwd()), "_vs_")[[1]])
file_namings = file_namings %>% filter(V1 %in% comparison)
condition1_files = list.files("../../quantification.dir", pattern=as.character(file_namings[1,2]), recursive=T)
condition2_files = list.files("../../quantification.dir", pattern=as.character(file_namings[2,2]), recursive=T)

condition1_files = condition1_files[grepl("/", condition1_files)]
condition2_files = condition2_files[grepl("/", condition2_files)]

condition1_filenames = sapply(condition1_files, function(x) str_split(substr(x, 0, nchar(x)-3),"/")[[1]][1])
condition2_filenames = sapply(condition2_files, function(x) str_split(substr(x, 0, nchar(x)-3),"/")[[1]][1])

condition1_files = paste0(quant_dir, "/", condition1_files)
condition2_files = paste0(quant_dir, "/", condition2_files)

#create basic sample table for condition 1 with var1 set to comparison[1].
sample_table_1 = data.frame(files=condition1_files, sample_id=condition1_filenames) %>% 
  mutate(files = as.character(condition1_files)) %>% mutate(var1 = comparison[1]) %>%
  transmute(names = sample_id,
            var1 = as.factor(var1),
            files = files)

sample_table_1 = sample_table_1 %>% mutate(identifier = (str_split(names, "-")%>%unlist())[1])

#create basic sample table for condition 2 with var1 set to comparison[2].
sample_table_2 = data.frame(files=condition2_files, sample_id=condition2_filenames) %>% 
  mutate(files = as.character(condition2_files)) %>% mutate(var1 = comparison[2]) %>%
  transmute(names = sample_id,
            var1 = as.factor(var1),
            files = files) 

sample_table_2 = sample_table_2 %>% mutate(identifier = (str_split(names, "-")%>%unlist())[1])

#merge the 2 sample tables
sample_table = rbind(sample_table_1, sample_table_2)
```

How many in each condition

```{r table_of_conditions}
table(sample_table$var1)
```

Check files exist

```{r check_exists}
all(file.exists(sample_table$files))
```

If data is paired (by identifier) then remove those where there is only 1 of the 2 present (i.e. filtered at source)

```{r filter_for_pairs}
if(pipeline_yml$dtu$swish_settings$paired == TRUE){
summarized_sample_table = sample_table %>% group_by(identifier) %>% summarize(n=n()) %>% dplyr::filter(n==2) %>% dplyr::select(identifier) %>% unlist() %>% unname()

sample_table = sample_table %>% dplyr::filter(identifier %in% summarized_sample_table)
}
```

Import with tximeta

```{r import_with_tximeta}
library(SummarizedExperiment)

#make the linkedTxome
indexDir = file.path("../../salmon_index/agg-agg-agg.gtf.salmon.index")
#first run "bash remove_non_stranded.sh"
gtfPath = file.path("../../export/agg-agg-agg-strandedOnly.gtf")
fastaPath = file.path("../../salmon_index/agg-agg-aggtranscripts.fasta")
tmp = tempdir()
jsonFile = file.path(tmp, paste0(basename(indexDir), ".json"))
library(ensembldb)
makeLinkedTxome(indexDir = indexDir,
                source = "ModifiedEnsembl", organism = "Homo sapien",
                release = "85", genome = "GRCh38",
                fasta=fastaPath, gtf=gtfPath,
                jsonFile = jsonFile)
se = tximeta(sample_table, tx2gene="../../expression.dir/csvdb_files/tx2gene.txt")
```

Assays, should list infReps

```{r assaynames}
assayNames(se)
```

DTU:

```{r swish_DTU_scale_inf_reps}
se = scaleInfReps(se)
```

```{r swish_DTU_label_keep_and_filter}
se = labelKeep(se)
se = se[mcols(se)$keep,]
```

```{r swish_isoformProportions}
set.seed(1)
iso = isoformProportions(se)
```

```{r swish_DTU}
if(pipeline_yml$dtu$swish_settings$paired == TRUE){
  iso = swish(iso, x="var1", pair="identifier")
} else {
  iso = swish(iso, x="var1")
}
table(mcols(iso)$qvalue<0.05)
```

```{r head_mcols}
head(mcols(iso))
```

```{r head_sigDTU}
sig_DTU = as.data.frame(mcols(iso)) %>% dplyr::filter(qvalue<0.05 & pvalue<0.05) %>% arrange(qvalue)
head(sig_DTU)
print(paste0("Number of significant DTU transcripts: ", nrow(sig_DTU)))
print(paste0("Number of significant DTU genes: ", nrow(sig_DTU %>% dplyr::select(gene_id) %>% dplyr::distinct())))
sig_DTU = sig_DTU %>% dplyr::select(-c(gene_id, tx_id, gene))
tx2gene = read.delim("../../expression.dir/csvdb_files/tx2gene.txt")
tx2gene = tx2gene %>% dplyr::filter(transcript_id %in% sig_DTU$tx_name)
sig_DTU = left_join(sig_DTU, tx2gene, by=c("tx_name"="transcript_id"))
sig_DTU = sig_DTU %>% dplyr::rename(tx_id = tx_name) %>% dplyr::rename(gene_id = match_gene_id)
```

```{r save}
write.csv(sig_DTU, "swish_sig_DTU.csv", quote=FALSE)
save.image("swishDTU.RData")
```